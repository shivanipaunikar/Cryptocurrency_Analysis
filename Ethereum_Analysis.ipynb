{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3630f07",
   "metadata": {},
   "source": [
    "# Ethereum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa50370",
   "metadata": {},
   "source": [
    "# Data collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a5610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Users/shivanipaunikar/Downloads/Project- crypto/EC.zst\n",
      "Completed: /Users/shivanipaunikar/Downloads/Project- crypto/EC.zst -> /Users/shivanipaunikar/Downloads/Project- crypto/output/EC.json\n",
      "Processing: /Users/shivanipaunikar/Downloads/Project- crypto/ES.zst\n",
      "Completed: /Users/shivanipaunikar/Downloads/Project- crypto/ES.zst -> /Users/shivanipaunikar/Downloads/Project- crypto/output/ES.json\n",
      "All files processed.\n"
     ]
    }
   ],
   "source": [
    "import zstandard as zstd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def decompress_zst(input_file, output_file, max_samples):\n",
    "    with open(input_file, 'rb') as compressed_file:\n",
    "        decomp = zstd.ZstdDecompressor()\n",
    "        with open(output_file, 'wb') as output:\n",
    "            total_samples = 0\n",
    "            for chunk in decomp.read_to_iter(compressed_file):\n",
    "                output.write(chunk)\n",
    "                total_samples += chunk.count(b'\\n')\n",
    "                if total_samples >= max_samples:\n",
    "                    break\n",
    "\n",
    "# List of input files\n",
    "input_files = ['/Users/shivanipaunikar/Downloads/Project- crypto/EC.zst', '/Users/shivanipaunikar/Downloads/Project- crypto/ES.zst']\n",
    "\n",
    "# Output directory where decompressed files will be stored\n",
    "output_directory = '/Users/shivanipaunikar/Downloads/Project- crypto/output'\n",
    "\n",
    "# Maximum number of samples you want to use\n",
    "max_samples = 5000\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop through each input file and decompress\n",
    "for input_file in input_files:\n",
    "    # Generate the output file path by removing the .zst extension and adding .json\n",
    "    output_file = os.path.join(output_directory, os.path.splitext(os.path.basename(input_file))[0] + '.json')\n",
    "    \n",
    "    print(f\"Processing: {input_file}\")\n",
    "    \n",
    "    # Decompress the input file, limiting to max_samples, and save it to the output file path\n",
    "    decompress_zst(input_file, output_file, max_samples)\n",
    "    \n",
    "    print(f\"Completed: {input_file} -> {output_file}\")\n",
    "\n",
    "print(\"All files processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330f077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line due to JSON syntax error: {\"link_flair_text\":null,\"thumbnail\":\"default\",\"quarantine\":false,\"downs\":0,\"num_comments\":22,\"domain\":\"otlw.co\",\"distinguished\":null,\"secure_media\":null,\"title\":\"Building a decentralized educational system\",\"id\":\"3jq91b\",\"is_self\":false,\"hide_score\":false,\"author_flair_css_class\":null,\"subreddit\":\"ethereum\",\"media_embed\":{},\"media\":null,\"edited\":false,\"created\":1441476416,\"created_utc\":\"1441447616\",\"from_id\":null,\"s\n",
      "Skipping line due to JSON syntax error: {\"author\":\"mrkellis\",\"created_utc\":\"1400540199\",\"removal_reason\":null,\"distinguished\":null,\"subreddit\":\"ethereum\",\"link_id\":\"t3_25y4le\",\"downs\":0,\"retrieved_on\":1433868840,\"edited\":false,\"body\":\"&gt; All traffic between Ethereum nodes is encrypted via a public key\\n\\nIs the key being rotated PFS style? Can Ethereum use something like [Noise](https://github.com/trevp\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Define the output directory where the JSON files were decompressed\n",
    "output_directory = '/Users/shivanipaunikar/Downloads/Project- crypto/output'\n",
    "\n",
    "# Function to fix JSON syntax errors\n",
    "def fix_json_syntax(input_file, output_file):\n",
    "    with open(input_file, 'r') as input_json, open(output_file, 'w') as output_json:\n",
    "        for line in input_json:\n",
    "            try:\n",
    "                json_obj = json.loads(line)\n",
    "                corrected_line = json.dumps(json_obj) + '\\n'\n",
    "                output_json.write(corrected_line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                # Handle JSON syntax errors here or simply skip problematic lines\n",
    "                print(f\"Skipping line due to JSON syntax error: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "# Specify your input and output file paths for fixing 'ES.json' syntax\n",
    "input_file_path_bs = os.path.join(output_directory, 'ES.json')\n",
    "output_file_path_bs = os.path.join(output_directory, 'ES_fixed.json')\n",
    "\n",
    "# Call the function to fix JSON syntax errors in 'Bs.json'\n",
    "fix_json_syntax(input_file_path_bs, output_file_path_bs)\n",
    "\n",
    "# Specify your input and output file paths for fixing 'Bc.json' syntax\n",
    "input_file_path_bc = os.path.join(output_directory, 'EC.json')\n",
    "output_file_path_bc = os.path.join(output_directory, 'EC_fixed.json')\n",
    "\n",
    "# Call the function to fix JSON syntax errors in 'Bc.json'\n",
    "fix_json_syntax(input_file_path_bc, output_file_path_bc)\n",
    "\n",
    "# Define a function to read JSON data line by line\n",
    "def read_json_lines(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            yield json.loads(line)\n",
    "\n",
    "# Use os.path.join to construct file paths\n",
    "submission_data = list(read_json_lines(output_file_path_bs))  \n",
    "comment_data = list(read_json_lines(output_file_path_bc)) \n",
    "\n",
    "# Create DataFrames\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "comment_df = pd.DataFrame(comment_data)\n",
    "\n",
    "# Filter for Bitcoin-related data (you may need to adjust the filter)\n",
    "Ethereum_submissions = submission_df[submission_df['title'].str.contains('Ethereum', case=False, na=False)]\n",
    "Ethereum_comments = comment_df[comment_df['body'].str.contains('Ethereum', case=False, na=False)]\n",
    "\n",
    "# Sample 5000 observations with replacement\n",
    "Ethereum_submissions_sample = Ethereum_submissions.sample(n=5000, replace=True)\n",
    "Ethereum_comments_sample = Ethereum_comments.sample(n=5000, replace=True)\n",
    "\n",
    "# Export to CSV\n",
    "Ethereum_submissions_sample.to_csv('Ethereum_submissions_sample.csv', index=False)\n",
    "Ethereum_comments_sample.to_csv('Ethereum_comments_sample.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb8233",
   "metadata": {},
   "source": [
    "# Summary stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450ccc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "Ethereum_submissions_df = pd.read_csv('Ethereum_submissions_sample.csv')\n",
    "Ethereum_comments_df = pd.read_csv('Ethereum_comments_sample.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7dc050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Ethereum_submissions_df:\n",
      "Index(['quarantine', 'edited', 'score', 'stickied', 'subreddit_id', 'created',\n",
      "       'from_kind', 'secure_media', 'url', 'from_id', 'is_self', 'author',\n",
      "       'from', 'id', 'archived', 'name', 'link_flair_css_class', 'gilded',\n",
      "       'over_18', 'saved', 'author_flair_css_class', 'num_comments',\n",
      "       'retrieved_on', 'ups', 'media', 'selftext', 'permalink',\n",
      "       'link_flair_text', 'secure_media_embed', 'title', 'distinguished',\n",
      "       'thumbnail', 'downs', 'hide_score', 'domain', 'subreddit',\n",
      "       'media_embed', 'author_flair_text', 'created_utc', 'post_hint',\n",
      "       'preview', 'locked'],\n",
      "      dtype='object')\n",
      "Sample data in Ethereum_submissions_df:\n",
      "   quarantine edited  score  stickied subreddit_id     created  from_kind  \\\n",
      "0       False  False     22     False     t5_2zf9m  1437513314        NaN   \n",
      "1       False  False      6     False     t5_2zf9m  1424877407        NaN   \n",
      "2       False  False      3     False     t5_2zf9m  1438186037        NaN   \n",
      "3       False  False      7     False     t5_2zf9m  1438518899        NaN   \n",
      "4       False  False     17     False     t5_2zf9m  1393716027        NaN   \n",
      "\n",
      "                                        secure_media  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  {'oembed': {'title': 'Keiser Report: New Crypt...   \n",
      "\n",
      "                                                 url  from_id  ...  downs  \\\n",
      "0  http://www.reddit.com/r/ethereum/comments/3e42...      NaN  ...      0   \n",
      "1  http://www.reddit.com/r/ethereum/comments/2x49...      NaN  ...      0   \n",
      "2  http://www.reddit.com/r/ethereum/comments/3f1b...      NaN  ...      0   \n",
      "3  http://www.reddit.com/r/ethereum/comments/3fi1...      NaN  ...      0   \n",
      "4                http://youtu.be/hdAnyC45ZbU?t=12m2s      NaN  ...      0   \n",
      "\n",
      "  hide_score         domain subreddit  \\\n",
      "0      False  self.ethereum  ethereum   \n",
      "1      False  self.ethereum  ethereum   \n",
      "2      False  self.ethereum  ethereum   \n",
      "3      False  self.ethereum  ethereum   \n",
      "4      False       youtu.be  ethereum   \n",
      "\n",
      "                                         media_embed author_flair_text  \\\n",
      "0                                                 {}               NaN   \n",
      "1                                                 {}               NaN   \n",
      "2                                                 {}               NaN   \n",
      "3                                                 {}               NaN   \n",
      "4  {'width': 600, 'height': 338, 'content': '&lt;...               NaN   \n",
      "\n",
      "   created_utc  post_hint  preview  locked  \n",
      "0   1437509714        NaN      NaN     NaN  \n",
      "1   1424877407        NaN      NaN     NaN  \n",
      "2   1438182437        NaN      NaN     NaN  \n",
      "3   1438515299        NaN      NaN     NaN  \n",
      "4   1393716027        NaN      NaN     NaN  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "Columns in Ethereum_comments_df:\n",
      "Index(['body', 'downs', 'name', 'link_id', 'parent_id', 'edited',\n",
      "       'distinguished', 'ups', 'score_hidden', 'author_flair_text',\n",
      "       'retrieved_on', 'created_utc', 'author', 'controversiality',\n",
      "       'subreddit_id', 'subreddit', 'removal_reason', 'score',\n",
      "       'author_flair_css_class', 'id', 'archived', 'gilded'],\n",
      "      dtype='object')\n",
      "Sample data in Ethereum_comments_df:\n",
      "                                                body  downs        name  \\\n",
      "0  Most likely its either scrypt or sha-256 (prob...      0  t1_cextjju   \n",
      "1  Food for thought: \\n\\nUnreal creates a game en...      0  t1_cgyhbzz   \n",
      "2  A little harsh, but true words, IMO.\\n\\nFirst ...      0  t1_cg313cv   \n",
      "3  Ethereum has the potential to form into a very...      0  t1_cfz8u28   \n",
      "4  A lot of this looks like fun stuff to just rea...      0  t1_cgqca5j   \n",
      "\n",
      "     link_id   parent_id edited  distinguished  ups  score_hidden  \\\n",
      "0  t3_1vxdat  t1_cexobvx  False            NaN    1         False   \n",
      "1  t3_23hys7  t1_cgyg954  False            NaN    2         False   \n",
      "2  t3_20aktc  t1_cg1t8rv  False            NaN    1         False   \n",
      "3  t3_1zxlm7  t1_cfz6ges  False            NaN    0         False   \n",
      "4  t3_22n2uf  t1_cgq1frz  False            NaN    3         False   \n",
      "\n",
      "  author_flair_text  ...           author  controversiality subreddit_id  \\\n",
      "0               NaN  ...  CareerBitcoiner                 0     t5_2zf9m   \n",
      "1               NaN  ...      Sound_Paper                 0     t5_2zf9m   \n",
      "2               NaN  ...        anfedorov                 0     t5_2zf9m   \n",
      "3               NaN  ...            Tas_P                 0     t5_2zf9m   \n",
      "4               NaN  ...         noninono                 0     t5_2zf9m   \n",
      "\n",
      "   subreddit removal_reason score  author_flair_css_class       id  archived  \\\n",
      "0   ethereum            NaN     1                     NaN  cextjju      True   \n",
      "1   ethereum            NaN     2                     NaN  cgyhbzz      True   \n",
      "2   ethereum            NaN     1                     NaN  cg313cv      True   \n",
      "3   ethereum            NaN     0                     NaN  cfz8u28      True   \n",
      "4   ethereum            NaN     3                     NaN  cgqca5j      True   \n",
      "\n",
      "  gilded  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the columns of the DataFrame\n",
    "print(\"Columns in Ethereum_submissions_df:\")\n",
    "print(Ethereum_submissions_df.columns)\n",
    "\n",
    "# Display a sample of the DataFrame\n",
    "print(\"Sample data in Ethereum_submissions_df:\")\n",
    "print(Ethereum_submissions_df.head())\n",
    "\n",
    "# Repeat the same for Ethereum_comments_df if needed\n",
    "print(\"Columns in Ethereum_comments_df:\")\n",
    "print(Ethereum_comments_df.columns)\n",
    "\n",
    "print(\"Sample data in Ethereum_comments_df:\")\n",
    "print(Ethereum_comments_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf80499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of dates available in Ethereum_submissions_df: (Timestamp('2014-01-04 01:42:51'), Timestamp('2015-09-04 17:38:42'))\n",
      "Range of dates available in Ethereum_comments_df: (Timestamp('2014-01-05 19:26:46'), Timestamp('2014-05-19 17:59:11'))\n",
      "\n",
      "Number of posts per day in Ethereum_submissions_df:\n",
      "created_utc\n",
      "2014-01-04     1\n",
      "2014-01-11    10\n",
      "2014-01-12    12\n",
      "2014-01-13     2\n",
      "2014-01-14    23\n",
      "              ..\n",
      "2015-08-31    22\n",
      "2015-09-01    17\n",
      "2015-09-02    29\n",
      "2015-09-03     7\n",
      "2015-09-04    27\n",
      "Length: 505, dtype: int64\n",
      "\n",
      "Number of comments per day in Ethereum_comments_df:\n",
      "created_utc\n",
      "2014-01-05     4\n",
      "2014-01-10     9\n",
      "2014-01-11    23\n",
      "2014-01-12    20\n",
      "2014-01-13    35\n",
      "              ..\n",
      "2014-05-15    21\n",
      "2014-05-16    16\n",
      "2014-05-17    11\n",
      "2014-05-18    21\n",
      "2014-05-19    35\n",
      "Length: 130, dtype: int64\n",
      "\n",
      "Number of unique authors per day in Ethereum_submissions_df:\n",
      "created_utc\n",
      "2014-01-04     1\n",
      "2014-01-11     2\n",
      "2014-01-12     5\n",
      "2014-01-13     1\n",
      "2014-01-14     4\n",
      "              ..\n",
      "2015-08-31     7\n",
      "2015-09-01     6\n",
      "2015-09-02    13\n",
      "2015-09-03     2\n",
      "2015-09-04     8\n",
      "Name: author, Length: 505, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into DataFrames (assuming you already have them loaded)\n",
    "Ethereum_submissions_df = pd.read_csv('Ethereum_submissions_sample.csv')\n",
    "Ethereum_comments_df = pd.read_csv('Ethereum_comments_sample.csv')\n",
    "\n",
    "# Convert 'created_utc' columns to datetime objects\n",
    "Ethereum_submissions_df['created_utc'] = pd.to_datetime(Ethereum_submissions_df['created_utc'], unit='s')\n",
    "Ethereum_comments_df['created_utc'] = pd.to_datetime(Ethereum_comments_df['created_utc'], unit='s')\n",
    "\n",
    "# Calculate the range of dates available\n",
    "date_range_submissions = Ethereum_submissions_df['created_utc'].min(), Ethereum_submissions_df['created_utc'].max()\n",
    "date_range_comments = Ethereum_comments_df['created_utc'].min(), Ethereum_comments_df['created_utc'].max()\n",
    "\n",
    "print(\"Range of dates available in Ethereum_submissions_df:\", date_range_submissions)\n",
    "print(\"Range of dates available in Ethereum_comments_df:\", date_range_comments)\n",
    "\n",
    "# Calculate the number of posts, comments, and authors for each day\n",
    "posts_per_day_submissions = Ethereum_submissions_df.groupby(Ethereum_submissions_df['created_utc'].dt.date).size()\n",
    "comments_per_day = Ethereum_comments_df.groupby(Ethereum_comments_df['created_utc'].dt.date).size()\n",
    "unique_authors_per_day_submissions = Ethereum_submissions_df.groupby(Ethereum_submissions_df['created_utc'].dt.date)['author'].nunique()\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nNumber of posts per day in Ethereum_submissions_df:\")\n",
    "print(posts_per_day_submissions)\n",
    "print(\"\\nNumber of comments per day in Ethereum_comments_df:\")\n",
    "print(comments_per_day)\n",
    "print(\"\\nNumber of unique authors per day in Ethereum_submissions_df:\")\n",
    "print(unique_authors_per_day_submissions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb9027",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f4177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5571d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into DataFrames (assuming you already have them loaded)\n",
    "Ethereum_submissions_df = pd.read_csv('Ethereum_submissions_sample.csv')\n",
    "Ethereum_comments_df = pd.read_csv('Ethereum_comments_sample.csv')\n",
    "\n",
    "# Convert 'created_utc' columns to datetime objects\n",
    "Ethereum_submissions_df['created_utc'] = pd.to_datetime(Ethereum_submissions_df['created_utc'], unit='s')\n",
    "Ethereum_comments_df['created_utc'] = pd.to_datetime(Ethereum_comments_df['created_utc'], unit='s')\n",
    "\n",
    "# Combine comments and submissions text\n",
    "Ethereum_text = Ethereum_submissions_df['selftext'].dropna().tolist() + Ethereum_comments_df['body'].dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95acf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shivanipaunikar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivanipaunikar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "Ethereum_text = [preprocess_text(text) for text in Ethereum_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6217e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b497cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF vectorization\n",
    "Ethereum_tfidf = tfidf_vectorizer.fit_transform([' '.join(tokens) for tokens in Ethereum_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7732da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim matplotlib pyLDAvis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of preprocessed tokens called 'bitcoin_text'\n",
    "# You can replace 'bitcoin_text' with your actual data\n",
    "dictionary = Dictionary([tokens for tokens in bitcoin_text])\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in bitcoin_text]\n",
    "\n",
    "# Perform LDA topic modeling\n",
    "lda_model_bitcoin = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddff046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Assuming you have a list of preprocessed tokens called 'Ethereum_text'\n",
    "# You can replace 'Ethereum_text' with your actual data\n",
    "dictionary = Dictionary([tokens for tokens in Ethereum_text])\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in Ethereum_text]\n",
    "\n",
    "# Perform LDA topic modeling\n",
    "lda_model_Ethereum = LdaModel(corpus=corpus, id2word=dictionary, num_topics=12, passes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f974c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list of preprocessed tokens called 'Ethereum_text'\n",
    "# You can replace 'Ethereum_text' with your actual data\n",
    "dictionary = Dictionary([tokens for tokens in Ethereum_text])\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in Ethereum_text]\n",
    "\n",
    "# Initialize lists to store coherence scores for different topic numbers\n",
    "coherence_scores = []\n",
    "num_topics_list = range(2, 21)  # You can adjust the range of topic numbers\n",
    "\n",
    "# Iterate through different numbers of topics\n",
    "for num_topics in num_topics_list:\n",
    "    lda_model_Ethereum = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=2)\n",
    "    \n",
    "    # Calculate the coherence score\n",
    "    coherence_model = CoherenceModel(model=lda_model_Ethereum, texts=Ethereum_text, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    \n",
    "    coherence_scores.append(coherence_score)\n",
    "\n",
    "# Plot the coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_topics_list, coherence_scores, marker='o')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.title(\"Coherence Score vs. Number of Topics\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topics generated by the LDA model\n",
    "topics = lda_model_Ethereum.print_topics(num_words=12)  # You can adjust the number of words per topic\n",
    "for topic in topics:\n",
    "    print(topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94a0a7",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48761562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Combine Ethereum submissions and comments text into a single list\n",
    "Ethereum_text = Ethereum_submissions_df['selftext'].dropna().tolist() + Ethereum_comments_df['body'].dropna().tolist()\n",
    "\n",
    "# Preprocess the text data (if you haven't done this already)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)  # Join tokens into a single string\n",
    "\n",
    "Ethereum_text = [preprocess_text(text) for text in Ethereum_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c161cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get sentiment\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "\n",
    "    if polarity > 0.1:\n",
    "        return \"positive\"\n",
    "    elif polarity < -0.1:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241bed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment analysis to your preprocessed text data\n",
    "sentiments = [get_sentiment(text) for text in Ethereum_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store sentiments (optional)\n",
    "sentiments_df = pd.DataFrame({'Sentiment': sentiments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print or analyze the sentiment results as needed\n",
    "print(sentiments_df['Sentiment'].value_counts())  # Display sentiment counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few comments with their sentiments\n",
    "for i, comment in enumerate(Ethereum_comments_df['body'].dropna()):\n",
    "    if i >= 5:  # Print the first 5 comments\n",
    "        break\n",
    "    print(f\"Comment {i + 1}:\")\n",
    "    print(\"Text:\", comment)\n",
    "    print(\"Sentiment:\", sentiments[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already performed sentiment analysis and have a DataFrame 'sentiments_df'\n",
    "# with a 'Sentiment' column containing sentiment labels (positive, negative, neutral)\n",
    "\n",
    "# Count the occurrences of each sentiment label\n",
    "sentiment_counts = sentiments_df['Sentiment'].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'], alpha=0.7)\n",
    "plt.title('Sentiment Analysis of Ethereum Comments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Annotate the bars with counts\n",
    "for i, count in enumerate(sentiment_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f73a8",
   "metadata": {},
   "source": [
    "# Emotion Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"michellejieli/emotion_text_classifier\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_emotion(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    emotion_labels = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "    return emotion_labels[predicted_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ethereum_comments_df['emotion'] = Ethereum_comments_df['cleaned_text'].apply(get_emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the occurrences of each emotion label\n",
    "emotion_counts = Ethereum_comments_df['emotion'].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "emotion_counts.plot(kind='bar', color=['red', 'blue', 'green', 'purple', 'orange'], alpha=0.7)\n",
    "plt.title('Emotional Analysis of Ethereum Comments')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Annotate the bars with counts\n",
    "for i, count in enumerate(emotion_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
